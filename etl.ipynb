{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Capstone Project\n",
    "\n",
    "## Purpose/Scope\n",
    "This project will be to import, clean, and link supplied data sets from Udacity for further examination by Data Scientists for analytical information regarding immigration as it relates to  airport/port of arrival city with additional data on the demographic data of the port of arrival. The primary use case for this will be to analyze immigration patterns into certain ports of entry as they relate to the country of residence and whether or not this is a personal, school, or business reason for visiting the US. \n",
    "\n",
    "Spark will be the analysis tool of choice due to it's ability to handle Big Data (many millions+) of rows well, especially if deployed to a cluster environment. \n",
    "\n",
    "## Data\n",
    "\n",
    "Datasets were provided by Udacity from other open source repositories. \n",
    "* Airport Code Table - Table of Airport Codes and the corresponding city & basic city metadata - Source: [Our Airports](http://ourairports.com/data/) via [DataHub](https://datahub.io/core/airport-codes#data)\n",
    "* World Temperature Data - Data back to the 1700's for many world cities. - Source: [Berkeley Earth](http://berkeleyearth.org/) via [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data)\n",
    "* US City Demographic Data - Demographics/Population data on most US Cities and CDP's from [US Census Bureau](https://www.census.gov/data/developers/about/terms-of-service.html) via [OpenDataSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/table/?dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6InVzLWNpdGllcy1kZW1vZ3JhcGhpY3MiLCJvcHRpb25zIjp7fX0sImNoYXJ0cyI6W3siYWxpZ25Nb250aCI6dHJ1ZSwidHlwZSI6ImNvbHVtbiIsImZ1bmMiOiJBVkciLCJ5QXhpcyI6Im1lZGlhbl9hZ2UiLCJzY2llbnRpZmljRGlzcGxheSI6dHJ1ZSwiY29sb3IiOiIjRkY1MTVBIn1dLCJ4QXhpcyI6ImNpdHkiLCJtYXhwb2ludHMiOjUwLCJzb3J0IjoiIn1dLCJ0aW1lc2NhbGUiOiIiLCJkaXNwbGF5TGVnZW5kIjp0cnVlLCJhbGlnbk1vbnRoIjp0cnVlfQ%3D%3D)\n",
    "* I94 Immigration Data - Data on Immigration/Visitation in April 2016 from the Department of Commerce. Includes some demographic data on visitor. Original data set no longer available online, but provided by Udacity as an archive in Parquet format. - Current program site source: [I91 Arrivals Program](https://www.trade.gov/i-94-arrivals-program)\n",
    "\n",
    "\n",
    "## Setup\n",
    "Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType, DecimalType, TimestampType\n",
    "from datetime import date, datetime, timedelta\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Set output location / AWS Credentials (alternatively, set in a config file). For the purposes of testing and cost savings, files are loaded in current state to a my_local_data folder, but changing the comments will result in an output to an Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_location = 'my_local_data/'\n",
    "#output_location = 's3a://AWSBUCKETNAME/AWSKEYNAME'\n",
    "#os.environ[\"AWS_ACCESS_KEY_ID\"]= 'YOURKEY'\n",
    "#os.environ[\"AWS_SECRET_ACCESS_KEY\"] = 'YOURSECRET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Build initial spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Setup Date Function for Converting SAS Date formats to Regular Date format (SAS days are # of days since beginning of 1960)\n",
    "* Quality Check Function For confirming table information and column information\n",
    "* Name function to return dataframe name when passed as an argument into another function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(TimestampType())\n",
    "def sas_date (mydate):\n",
    "    if mydate is None:\n",
    "        z = None\n",
    "    else: \n",
    "        z = datetime(1960,1,1) + timedelta(days=int(mydate))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#This function provided on Stack Overflow to get a dataframe name when the object itself is passed\n",
    "# as an argument. Written/provided by cors https://stackoverflow.com/a/54138398\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def qualityCheck(a):\n",
    "    # Function takes a list of lists as a parameter, with the first element of the\n",
    "    # sublist being a table DF and all other values (unlimited) being column/field names quoted.\n",
    "    # Example: [[table_name,\"primaryKeyName\",\"secondFieldName\"], [table_name2,\"columnA\"]]\n",
    "    # Quality Check will \n",
    "    #   A) Verify the DF table has 1 or more records\n",
    "    #   B) Verify each passed field/column has no null records\n",
    "    \n",
    "    errors = []\n",
    "    for i in range(len(a)):\n",
    "        table = a[i][0]\n",
    "        tableName = get_df_name(table)\n",
    "        print (\"Checking table name {}\".format( tableName ))\n",
    "        cnt = table.count()\n",
    "        if not cnt >= 1:\n",
    "            errors.append(\"{} FAILED. Expected more than 0 records. Received {} \".format(tableName, cnt))\n",
    "            print(\"  FAILED! {} expected more than 0 records. Received {} \".format(tableName, cnt))\n",
    "        else:\n",
    "            print (\"  SUCCESS! Found {} records.\".format(cnt))\n",
    "        for j in range(1, len(a[i])):\n",
    "            columnName = a[i][j]\n",
    "            print (\"  Checking column name {} for NULL values\".format( columnName ))\n",
    "            cnt = table.where(col(columnName).isNull()).count()\n",
    "            if cnt > 0:\n",
    "                errors.append(\"{}.{} Column FAILED. Expected 0 NULL records. Received {} \".format(tableName, columnName, cnt))\n",
    "                print(\"     FAILED! {} NULL Found.\".format(cnt))\n",
    "            else:\n",
    "                print(\"    SUCCESS! 0 NULL Found.\")\n",
    "    if len(errors) > 0:\n",
    "        raise ValueError(\"Errors found in data quality check.\\n{}\".format('\\n'.join(map(str, errors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Extract Data / Read In Data to Spark\n",
    "\n",
    "Import i94 data, run QC function, and preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94data =spark.read.parquet(\"./sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94data_revised = i94data.withColumn(\"departure_date\",sas_date(col(\"depdate\")))\n",
    "i94data_revised = i94data_revised.withColumn(\"arrival_date\",sas_date(col(\"arrdate\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name i94data_revised\n",
      "  SUCCESS! Found 3096313 records.\n",
      "  Checking column name cicid for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name arrival_date for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name admnum for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[i94data_revised, \"cicid\", \"arrival_date\",\"admnum\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>arrival_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>2016-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-05-17</td>\n",
       "      <td>2016-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-05-08</td>\n",
       "      <td>2016-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2016-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "      <td>2016-05-14</td>\n",
       "      <td>2016-04-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate     ...       biryear   dtaddto  gender insnum airline  \\\n",
       "0      CA  20582.0     ...        1976.0  10292016       F   None      QF   \n",
       "1      NV  20591.0     ...        1984.0  10292016       F   None      VA   \n",
       "2      WA  20582.0     ...        1987.0  10292016       M   None      DL   \n",
       "3      WA  20588.0     ...        1987.0  10292016       F   None      DL   \n",
       "4      WA  20588.0     ...        1988.0  10292016       M   None      DL   \n",
       "\n",
       "         admnum  fltno visatype departure_date arrival_date  \n",
       "0  9.495387e+10  00011       B1     2016-05-08   2016-04-30  \n",
       "1  9.495562e+10  00007       B1     2016-05-17   2016-04-30  \n",
       "2  9.495641e+10  00040       B1     2016-05-08   2016-04-30  \n",
       "3  9.495645e+10  00040       B1     2016-05-14   2016-04-30  \n",
       "4  9.495639e+10  00040       B1     2016-05-14   2016-04-30  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94data_revised.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Import City Demographics, filter out race information creating duplicate records (not needed for current scope), run QC function, and preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities=spark.read.csv(\"./us-cities-demographics.csv\", sep=';', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_cities_revised = us_cities.select('City',\n",
    " 'State',\n",
    " 'Median Age',\n",
    " 'Male Population',\n",
    " 'Female Population',\n",
    " 'Total Population',\n",
    " 'Number of Veterans',\n",
    " 'Foreign-born',\n",
    " 'Average Household Size',\n",
    " 'State Code').dropDuplicates().orderBy(\"state\",\"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name us_cities_revised\n",
      "  SUCCESS! Found 596 records.\n",
      "  Checking column name City for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name State Code for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[us_cities_revised, \"City\", \"State Code\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>35.6</td>\n",
       "      <td>102122</td>\n",
       "      <td>112789</td>\n",
       "      <td>214911</td>\n",
       "      <td>13212</td>\n",
       "      <td>8258</td>\n",
       "      <td>2.21</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dothan</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.9</td>\n",
       "      <td>32172</td>\n",
       "      <td>35364</td>\n",
       "      <td>67536</td>\n",
       "      <td>6334</td>\n",
       "      <td>1699</td>\n",
       "      <td>2.59</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huntsville</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.1</td>\n",
       "      <td>91764</td>\n",
       "      <td>97350</td>\n",
       "      <td>189114</td>\n",
       "      <td>16637</td>\n",
       "      <td>12691</td>\n",
       "      <td>2.18</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.0</td>\n",
       "      <td>91275</td>\n",
       "      <td>103030</td>\n",
       "      <td>194305</td>\n",
       "      <td>11939</td>\n",
       "      <td>7234</td>\n",
       "      <td>2.4</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City    State Median Age Male Population Female Population  \\\n",
       "0  Birmingham  Alabama       35.6          102122            112789   \n",
       "1      Dothan  Alabama       38.9           32172             35364   \n",
       "2      Hoover  Alabama       38.5           38040             46799   \n",
       "3  Huntsville  Alabama       38.1           91764             97350   \n",
       "4      Mobile  Alabama       38.0           91275            103030   \n",
       "\n",
       "  Total Population Number of Veterans Foreign-born Average Household Size  \\\n",
       "0           214911              13212         8258                   2.21   \n",
       "1            67536               6334         1699                   2.59   \n",
       "2            84839               4819         8229                   2.58   \n",
       "3           189114              16637        12691                   2.18   \n",
       "4           194305              11939         7234                    2.4   \n",
       "\n",
       "  State Code  \n",
       "0         AL  \n",
       "1         AL  \n",
       "2         AL  \n",
       "3         AL  \n",
       "4         AL  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_cities_revised.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Import Airport data, fix state column (from US-AL to AL), remove irregular types (immigration doesn't happen by balloon), and specify only airports with an iata_code (INS immigration does not traditionally happen at an airport small enough to not be iata coded). Finally, preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_airports=spark.read.csv(\"./airport-codes_csv.csv\", sep=',', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_airports_revised = us_airports.withColumn('state', regexp_replace(\"iso_region\",\"US-\",\"\")).\\\n",
    "                drop('iso_region').filter(us_airports.type != \"small_airport\").\\\n",
    "                filter(us_airports.type != \"heliport\").\\\n",
    "                filter(us_airports.type != \"closed\").\\\n",
    "                filter(us_airports.type != \"balloonport\").\\\n",
    "                filter(us_airports.type != \"seaplane_base\").\\\n",
    "                filter(us_airports.iso_country == \"US\").\\\n",
    "                filter(us_airports.iata_code.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name us_airports_revised\n",
      "  SUCCESS! Found 820 records.\n",
      "  Checking column name ident for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name iata_code for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name municipality for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name state for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[us_airports_revised, \"ident\", \"iata_code\",\"municipality\",\"state\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5A8</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Aleknagik / New Airport</td>\n",
       "      <td>66</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Aleknagik</td>\n",
       "      <td>5A8</td>\n",
       "      <td>WKK</td>\n",
       "      <td>5A8</td>\n",
       "      <td>-158.617996216, 59.2826004028</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KABE</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Lehigh Valley International Airport</td>\n",
       "      <td>393</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>KABE</td>\n",
       "      <td>ABE</td>\n",
       "      <td>ABE</td>\n",
       "      <td>-75.44080352783203, 40.652099609375</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KABI</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Abilene Regional Airport</td>\n",
       "      <td>1791</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>KABI</td>\n",
       "      <td>ABI</td>\n",
       "      <td>ABI</td>\n",
       "      <td>-99.68190002440001, 32.4113006592</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KABQ</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>Albuquerque International Sunport</td>\n",
       "      <td>5355</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>KABQ</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>ABQ</td>\n",
       "      <td>-106.609001, 35.040199</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KABR</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Aberdeen Regional Airport</td>\n",
       "      <td>1302</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>KABR</td>\n",
       "      <td>ABR</td>\n",
       "      <td>ABR</td>\n",
       "      <td>-98.42179870605469, 45.449100494384766</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident            type                                 name elevation_ft  \\\n",
       "0   5A8  medium_airport              Aleknagik / New Airport           66   \n",
       "1  KABE  medium_airport  Lehigh Valley International Airport          393   \n",
       "2  KABI  medium_airport             Abilene Regional Airport         1791   \n",
       "3  KABQ   large_airport    Albuquerque International Sunport         5355   \n",
       "4  KABR  medium_airport            Aberdeen Regional Airport         1302   \n",
       "\n",
       "  continent iso_country municipality gps_code iata_code local_code  \\\n",
       "0        NA          US    Aleknagik      5A8       WKK        5A8   \n",
       "1        NA          US    Allentown     KABE       ABE        ABE   \n",
       "2        NA          US      Abilene     KABI       ABI        ABI   \n",
       "3        NA          US  Albuquerque     KABQ       ABQ        ABQ   \n",
       "4        NA          US     Aberdeen     KABR       ABR        ABR   \n",
       "\n",
       "                              coordinates state  \n",
       "0           -158.617996216, 59.2826004028    AK  \n",
       "1     -75.44080352783203, 40.652099609375    PA  \n",
       "2       -99.68190002440001, 32.4113006592    TX  \n",
       "3                  -106.609001, 35.040199    NM  \n",
       "4  -98.42179870605469, 45.449100494384766    SD  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_airports_revised.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Import SAS Data Label file. \n",
    "\n",
    "The source of this function is Udacity Mentor  Anshul R on mentor help site https://knowledge.udacity.com/questions/125439 for Udacity student use.\n",
    "Decoding this file's irregular format was not in scope of the course, so I used the code provided with minimal modifications to bring the data into a proper Spark DF.\n",
    "\n",
    "Run quality checks on each, then preview new dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"ID\",StringType(),True), \\\n",
    "    StructField(\"Name\",StringType(),True), \\\n",
    "  ])\n",
    "\n",
    "with open('./I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "    f_content = f.read()\n",
    "    f_content = f_content.replace('\\t', '')\n",
    "def code_mapper(file, idx):\n",
    "    f_content2 = f_content[f_content.index(idx):]\n",
    "    f_content2 = f_content2[:f_content2.index(';')].split('\\n')\n",
    "    f_content2 = [i.replace(\"'\", \"\") for i in f_content2]\n",
    "    dic = [i.split('=') for i in f_content2[1:]]\n",
    "    dic = dict([str(i[0].strip()), i[1].strip()] for i in dic if len(i) == 2)\n",
    "    return dic\n",
    "i94cit_res = spark.createDataFrame(code_mapper(f_content, \"i94cntyl\").items(), schema)\n",
    "i94port = spark.createDataFrame(code_mapper(f_content, \"i94prtl\").items(), schema)\n",
    "i94mode = spark.createDataFrame(code_mapper(f_content, \"i94model\").items(), schema)\n",
    "i94addr = spark.createDataFrame(code_mapper(f_content, \"i94addrl\").items(), schema)\n",
    "i94mode = spark.createDataFrame(code_mapper(f_content, \"i94model\").items(), schema)\n",
    "i94visa = spark.createDataFrame(list(({'1':'Business',\n",
    "'2': 'Pleasure',\n",
    "'3' : 'Student'}).items()), schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Because the i94 table does not follow IATA naming, we will utilize the Port Table (derived from the SAS Label file above) to parse City and State. This can then be mapped with semi-resonable accuracy to the airport table if also filtering on the mode table to be air travel only. Remove entries that do not have a state code parseable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94port_revised = i94port.withColumn('City',split(i94port.Name,', ').getItem(0)).\\\n",
    "                                    withColumn('State',split(i94port.Name,', ').getItem(1)).\\\n",
    "                                    drop(\"Name\")\n",
    "i94port_revised = i94port_revised.filter(i94port_revised.State.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name i94port_revised\n",
      "  SUCCESS! Found 582 records.\n",
      "  Checking column name ID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name City for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name State for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[i94port_revised, \"ID\", \"City\", \"State\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name i94cit_res\n",
      "  SUCCESS! Found 289 records.\n",
      "  Checking column name ID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[i94cit_res, \"ID\", \"Name\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                      City State\n",
       "0  ALC                     ALCAN    AK\n",
       "1  ANC                 ANCHORAGE    AK\n",
       "2  BAR  BAKER AAF - BAKER ISLAND    AK\n",
       "3  DAC             DALTONS CACHE    AK\n",
       "4  PIZ    DEW STATION PT LAY DEW    AK"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94port_revised.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               Name\n",
       "0  582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1  236                                        AFGHANISTAN\n",
       "2  101                                            ALBANIA\n",
       "3  316                                            ALGERIA\n",
       "4  102                                            ANDORRA"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94cit_res.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name i94mode\n",
      "  SUCCESS! Found 4 records.\n",
      "  Checking column name ID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[i94mode, \"ID\", \"Name\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID          Name\n",
       "0  1           Air\n",
       "1  2           Sea\n",
       "2  3          Land\n",
       "3  9  Not reported"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94mode.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name i94addr\n",
      "  SUCCESS! Found 55 records.\n",
      "  Checking column name ID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[i94addr, \"ID\", \"Name\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID        Name\n",
       "0  AL     ALABAMA\n",
       "1  AK      ALASKA\n",
       "2  AZ     ARIZONA\n",
       "3  AR    ARKANSAS\n",
       "4  CA  CALIFORNIA"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94addr.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name i94visa\n",
      "  SUCCESS! Found 3 records.\n",
      "  Checking column name ID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[i94visa, \"ID\", \"Name\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID      Name\n",
       "0  1  Business\n",
       "1  2  Pleasure\n",
       "2  3   Student"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94visa.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name i94mode\n",
      "  SUCCESS! Found 4 records.\n",
      "  Checking column name ID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [[i94mode, \"ID\", \"Name\"]]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID          Name\n",
       "0  1           Air\n",
       "1  2           Sea\n",
       "2  3          Land\n",
       "3  9  Not reported"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94mode.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Data Model\n",
    "\n",
    "### Concept\n",
    "\n",
    "The model is made up by the previous defined dataframes:\n",
    "\n",
    "|Name|Data Type|Description|Assumptions|\n",
    "|---|----|---|----|\n",
    "|i94data|Fact Data|Travel/Immigration Data from USNTTO|cicid is a unique identifer per person|\n",
    "|i94visa|Dimension Data|Visa Type|\n",
    "\n",
    "|i94port|Dimension Data|Port of Entry|\n",
    "|i94mode|Dimension Data|Type of Travel Entry|\n",
    "|i94cit_res|Dimension Data|Origin/Country of Residence|\n",
    "|us_airports|Dimension Data|Listing of US Airpoprts|\n",
    "|us_cities|Dimension Data|Listing of US Cities|\n",
    "\n",
    "<!--|us_temp|Fact Data|Temperature by Month by City|-->\n",
    "<!--|i94addr|Dimension Data|State/Location of Destination|-->\n",
    "\n",
    "Data will be loaded from these staging df's into a proper star schema. Based on the data set having only one two updating table (immigration and less frequently updating, person) The primary fact table will be made up of actual immigrations, with dimensional tables for airport, time, country, mode of transportation, i94 port names, and visa type.\n",
    "\n",
    "<img src=\"dbSchema.png\" size = '30%'>\n",
    "<i><div style=\"text-align: right\">  Graphic built with https://dbdiagram.io/d </div></i>\n",
    "\n",
    "In a traditional ETL, we would perhaps be joining new data on some regular basis, requiring modification of the below ETL process ti import only new data. As it stands, this is a static data set, so a single insert is implied.\n",
    "\n",
    "\n",
    "### Transform / Define Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "person_table = i94data_revised.selectExpr(\"cicid as personID\", \"i94res as country\", \\\n",
    "                                  \"i94bir as age\", \"gender\",\"admnum as admissionId\", \"occup as occupation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_table = i94data_revised.selectExpr(\"arrival_date as arrivalDate\", \"year(arrival_date) as year\", \\\n",
    "                                        \"month(arrival_date) as month\", \"day(arrival_date) day\", \\\n",
    "                                        \"hour(arrival_date) as hour\", \"weekofyear(arrival_date) week\", \\\n",
    "                                        \"dayofweek(arrival_date) weekDay\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_table = i94cit_res.selectExpr(\"ID as countryID\", \"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_table = us_airports_revised.selectExpr(\"ident as airportID\", \"name as name\", \\\n",
    "                                   \"municipality as city\", \"state\", \"iata_code as iataCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_table = i94visa.selectExpr(\"ID as visaID\", \"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_table = i94port_revised.selectExpr(\"ID as portID\", \"City\", \"State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "mode_table = i94mode.selectExpr(\"ID as modeID\", \"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_fact_table = i94data_revised.selectExpr(\"cicid as personID\", \"departure_date\", \"arrival_date\", \\\n",
    "                           \"i94visa as visaTypeID\", \"i94port as portID\", \\\n",
    "                           \"airline as airlineName\", \"fltno as flightNumber\", \"admnum as admissionNumber\",\n",
    "                           \"i94mode as modeID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load / Quality Checks\n",
    "\n",
    "### Parquet Export/Imports\n",
    "Define tables to upload in spark/parquet. Count records going out, then read data back in and do another count to ensure everything is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "tables = [immigration_fact_table, port_table, time_table, \\\n",
    "          mode_table, country_table, visa_table, \\\n",
    "          airport_table, person_table]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 3096313 records from my_local_data/immigration_fact_table\n",
      "Exporting 582 records from my_local_data/port_table\n",
      "Exporting 30 records from my_local_data/time_table\n",
      "Exporting 4 records from my_local_data/mode_table\n",
      "Exporting 289 records from my_local_data/country_table\n",
      "Exporting 3 records from my_local_data/visa_table\n",
      "Exporting 820 records from my_local_data/airport_table\n",
      "Exporting 3096313 records from my_local_data/person_table\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for table in tables:\n",
    "        fullloc = output_location + get_df_name(table)\n",
    "        table.write.mode(\"overwrite\").parquet(fullloc)\n",
    "        print(\"Exporting {} records to {}\".format(table.count(),fullloc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_local_data/immigration_fact_table imported. 3096313 records found\n",
      "my_local_data/port_table imported. 582 records found\n",
      "my_local_data/time_table imported. 30 records found\n",
      "my_local_data/mode_table imported. 4 records found\n",
      "my_local_data/country_table imported. 289 records found\n",
      "my_local_data/visa_table imported. 3 records found\n",
      "my_local_data/airport_table imported. 820 records found\n",
      "my_local_data/person_table imported. 3096313 records found\n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "        fullloc = output_location + get_df_name(table)\n",
    "        table = spark.read.parquet(fullloc)\n",
    "        print(\"{} imported {} records\".format(fullloc, table.count()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking table name port_table\n",
      "  SUCCESS! Found 582 records.\n",
      "  Checking column name portID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "Checking table name mode_table\n",
      "  SUCCESS! Found 4 records.\n",
      "  Checking column name modeID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "Checking table name country_table\n",
      "  SUCCESS! Found 289 records.\n",
      "  Checking column name countryID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "Checking table name visa_table\n",
      "  SUCCESS! Found 3 records.\n",
      "  Checking column name visaID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name Name for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "Checking table name airport_table\n",
      "  SUCCESS! Found 820 records.\n",
      "  Checking column name airportID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name City for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name State for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "Checking table name person_table\n",
      "  SUCCESS! Found 3096313 records.\n",
      "  Checking column name personID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "Checking table name immigration_fact_table\n",
      "  SUCCESS! Found 3096313 records.\n",
      "  Checking column name personID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name arrival_date for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name portID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name visaTypeID for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n",
      "  Checking column name arrival_date for NULL values\n",
      "    SUCCESS! 0 NULL Found.\n"
     ]
    }
   ],
   "source": [
    "tableDataToCheck = [\n",
    "    [port_table, \"portID\", \"Name\"],\n",
    "    [mode_table, \"modeID\", \"Name\"],\n",
    "    [country_table, \"countryID\", \"Name\"],\n",
    "    [visa_table, \"visaID\", \"Name\"],\n",
    "    [airport_table, \"airportID\", \"City\", \"State\"],\n",
    "    [time_table, \"arrival_date\"],\n",
    "    [person_table, \"personID\"],\n",
    "    [immigration_fact_table, \"personID\", \"arrival_date\",\"portID\", \"visaTypeID\", \"arrival_date\"]\n",
    "]\n",
    "qualityCheck(tableDataToCheck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create Data Dictionary\n",
    "This is a one time process to create dictionary. It should be filled out manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary file already exists.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Data Dictionary\n",
       "## immigration_fact_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|personID|DoubleType|Person Table Reference ID|\n",
       "|departure_date|TimestampType|Date of Departure for Visitor|\n",
       "|arrival_date|TimestampType|Date of Arrival for Visitor|\n",
       "|visaTypeID|DoubleType|Visa Table Reference ID|\n",
       "|portID|StringType|Port Table Reference ID|\n",
       "|airlineName|StringType|Airline Code Name|\n",
       "|flightNumber|StringType|Airline Flight Number|\n",
       "|admissionNumber|DoubleType|Unique key for immigration entry|\n",
       "|modeID|DoubleType|Mode Table Reference ID|\n",
       "\n",
       "## port_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|portID|StringType|Primary Key Identifier|\n",
       "|City|StringType|Port of Entry City|\n",
       "|State|StringType|Port of Entry State|\n",
       "\n",
       "## time_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|arrivalDate|TimestampType|Primary Key Identifier|\n",
       "|year|IntegerType|Arrival Year|\n",
       "|month|IntegerType|Arrival Month|\n",
       "|day|IntegerType|Arrival Day|\n",
       "|hour|IntegerType|Arrival Hour|\n",
       "|week|IntegerType|Arrival Week|\n",
       "|weekDay|IntegerType|Arrival DayofWeek (1-7 Sun-Sat)|\n",
       "\n",
       "## mode_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|modeID|StringType|Primary Key Identifier|\n",
       "|Name|StringType|Mode of Transportation for Entry|\n",
       "\n",
       "## country_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|countryID|StringType|Primary Key Identifier|\n",
       "|Name|StringType|Country of Residence|\n",
       "\n",
       "## visa_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|visaID|StringType|Primary Key Identifier|\n",
       "|Name|StringType|Visa Type/Reason for Visit|\n",
       "\n",
       "## airport_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|airportID|StringType|Primary Key Identifier|\n",
       "|name|StringType|Airport Name|\n",
       "|city|StringType|Airport City|\n",
       "|state|StringType|Airport State|\n",
       "|iataCode|StringType|Airport IATA Code|\n",
       "\n",
       "## person_table\n",
       "\n",
       "|Name|Type|Description|\n",
       "|---|---|---|\n",
       "|personID|DoubleType|Primary Key Identifier|\n",
       "|country|DoubleType|Country Table Reference ID|\n",
       "|age|DoubleType|Person Age|\n",
       "|gender|StringType|Person Gender|\n",
       "|admissionId|DoubleType|Person Admission ID|\n",
       "|occupation|StringType|Person Occupation|\n",
       "\n",
       "</align>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "if not exists(\"dictionary.md\"):\n",
    "    f = open(\"dictionary.md\", \"x\")\n",
    "    f.write(\"# Data Dictionary\\n\\n\")\n",
    "    for table in tables:\n",
    "        f.write(\"##\" + get_df_name(table) + '\\n\\n')\n",
    "        f.write(\"|Name|Type|Description|\\n\")\n",
    "        f.write(\"|---|---|---|\\n\")\n",
    "        for field in table.schema.fields:\n",
    "            f.write(\"|\" + field.name + \"|\" + str(field.dataType) + \"||\\n\")\n",
    "        f.write (\"\\n\")\n",
    "    f.close()\n",
    "    print (\"Dictionary must be filled out with proper field descriptions! Open dictionary.md to continue.\")\n",
    "    \n",
    "else:\n",
    "    print (\"Dictionary file already exists.\")\n",
    "    display(Markdown(\"dictionary.md\"))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "The project required a definition and ETL of data of 1 million+ rows. Data was imported, scrubbed for known bad types of data, transformed to deal with incomplete/poor naming, brought into new data frames, and finally uploaded to the output location (local or AWS). From here, the files can be read back into spark and joined or queried as necessary. A common query would be to join Airport Data, Port Data, Immigration, and Person tables to get proper names of airports the visitors\n",
    "\n",
    "As this was a large data set, spark was a clear choice for dealing with a large number of records. Because of the parquet files, this could also be spun up into multiple instances easily on AWS clusters.\n",
    "\n",
    "This data should only be run once in it's current form due to the static nature of the data sources. However, if this were a regular update, once a month would likely suffice for new immigration data.\n",
    "\n",
    "### Scenarios\n",
    "* Data Increased by 100x? As this is a Spark Job, I do not forsee any issues based on this being an ETL process that uses Spark. The longest piece is the read and write of parquet data, which only takes a few minutes at the current step. Multiplying this by 100 would require the job to run for several hours, but this could likely be broken down into two or more ETL's for simultaneous runs\n",
    "* Pipline run at 7AM? This ETL only takes a few minutes to run, so this would not be a challenge as currently written. The only changes necessary would be accounting for new file names and potentially exporting files with a date component in the parquet name. This should be a scheduled job and not run manually. A prefernce would either be a scheduling engine application (such as crontab) or running in a workflow style ETL program like Apache Airflow.\n",
    "* 100+ People need access to data? Additional EMR clusters would need to be spun up to handle the additionial load, but no other changes would need to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
